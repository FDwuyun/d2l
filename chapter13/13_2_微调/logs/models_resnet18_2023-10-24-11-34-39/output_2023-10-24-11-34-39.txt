{'net': 'models_resnet18', 'weights': 'weights = models.ResNet18_Weights.IMAGENET1K_V1', 'num_gpus': 2, 'num_epochs': 10, 'batch_size': 128, 'lr': 0.001, 'weight_decay': 0.001, 'description': '微调，热狗识别'}
[2023-10-24-11-34-39] training on  [device(type='cuda', index=0), device(type='cuda', index=1)]
[2023-10-24-11-34-41] Each epoch includes 16 batches
tensor(32680.4355, device='cuda:0', grad_fn=<NllLossBackward0>) 69.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ac82b0>
tensor(4993.2261, device='cuda:0', grad_fn=<NllLossBackward0>) 58.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ac82b0>
tensor(1032.6804, device='cuda:0', grad_fn=<NllLossBackward0>) 67.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ac82b0>
tensor(1882.2627, device='cuda:0', grad_fn=<NllLossBackward0>) 69.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ac82b0>
tensor(1332.8390, device='cuda:0', grad_fn=<NllLossBackward0>) 66.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ac82b0>
tensor(239.7833, device='cuda:0', grad_fn=<NllLossBackward0>) 50.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2ac82b0>
[2023-10-24-11-34-55][epoch: 1] 13.527 sec train_loss 51.178, train_acc 0.500, valid_acc 0.500
tensor(377.4690, device='cuda:0', grad_fn=<NllLossBackward0>) 69.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0e880>
tensor(281.5125, device='cuda:0', grad_fn=<NllLossBackward0>) 82.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0e880>
tensor(94.5344, device='cuda:0', grad_fn=<NllLossBackward0>) 90.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0e880>
tensor(680.5908, device='cuda:0', grad_fn=<NllLossBackward0>) 72.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0e880>
tensor(196.4990, device='cuda:0', grad_fn=<NllLossBackward0>) 71.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0e880>
tensor(87.0760, device='cuda:0', grad_fn=<NllLossBackward0>) 61.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2a0e880>
[2023-10-24-11-35-06][epoch: 2] 25.252 sec train_loss 2.408, train_acc 0.611, valid_acc 0.764
tensor(93.1098, device='cuda:0', grad_fn=<NllLossBackward0>) 84.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20ac0>
tensor(214.3245, device='cuda:0', grad_fn=<NllLossBackward0>) 71.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20ac0>
tensor(153.4192, device='cuda:0', grad_fn=<NllLossBackward0>) 80.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20ac0>
tensor(152.4459, device='cuda:0', grad_fn=<NllLossBackward0>) 93.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20ac0>
tensor(98.6010, device='cuda:0', grad_fn=<NllLossBackward0>) 95.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20ac0>
tensor(68.0288, device='cuda:0', grad_fn=<NllLossBackward0>) 65.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2a20ac0>
[2023-10-24-11-35-18][epoch: 3] 36.973 sec train_loss 0.969, train_acc 0.663, valid_acc 0.733
tensor(117.8923, device='cuda:0', grad_fn=<NllLossBackward0>) 85.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ed3e80>
tensor(60.3631, device='cuda:0', grad_fn=<NllLossBackward0>) 96.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ed3e80>
tensor(362.6970, device='cuda:0', grad_fn=<NllLossBackward0>) 70.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ed3e80>
tensor(63.6557, device='cuda:0', grad_fn=<NllLossBackward0>) 99.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ed3e80>
tensor(76.4585, device='cuda:0', grad_fn=<NllLossBackward0>) 79.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ed3e80>
tensor(63.8899, device='cuda:0', grad_fn=<NllLossBackward0>) 61.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2ed3e80>
[2023-10-24-11-35-30][epoch: 4] 48.660 sec train_loss 0.943, train_acc 0.712, valid_acc 0.744
tensor(72.6687, device='cuda:0', grad_fn=<NllLossBackward0>) 100.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a38b50>
tensor(81.0954, device='cuda:0', grad_fn=<NllLossBackward0>) 103.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a38b50>
tensor(64.4071, device='cuda:0', grad_fn=<NllLossBackward0>) 98.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a38b50>
tensor(94.3255, device='cuda:0', grad_fn=<NllLossBackward0>) 89.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a38b50>
tensor(66.2448, device='cuda:0', grad_fn=<NllLossBackward0>) 97.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a38b50>
tensor(113.4996, device='cuda:0', grad_fn=<NllLossBackward0>) 61.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2a38b50>
[2023-10-24-11-35-41][epoch: 5] 60.381 sec train_loss 0.660, train_acc 0.773, valid_acc 0.731
tensor(98.4359, device='cuda:0', grad_fn=<NllLossBackward0>) 85.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ec5280>
tensor(55.7149, device='cuda:0', grad_fn=<NllLossBackward0>) 104.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ec5280>
tensor(92.8818, device='cuda:0', grad_fn=<NllLossBackward0>) 83.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ec5280>
tensor(874.8130, device='cuda:0', grad_fn=<NllLossBackward0>) 91.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ec5280>
tensor(230.6545, device='cuda:0', grad_fn=<NllLossBackward0>) 89.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2ec5280>
tensor(69.8957, device='cuda:0', grad_fn=<NllLossBackward0>) 57.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2ec5280>
[2023-10-24-11-35-53][epoch: 6] 72.271 sec train_loss 1.461, train_acc 0.717, valid_acc 0.500
tensor(2011.4963, device='cuda:0', grad_fn=<NllLossBackward0>) 66.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e35dc0>
tensor(86.6482, device='cuda:0', grad_fn=<NllLossBackward0>) 79.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e35dc0>
tensor(334.6712, device='cuda:0', grad_fn=<NllLossBackward0>) 88.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e35dc0>
tensor(141.7506, device='cuda:0', grad_fn=<NllLossBackward0>) 83.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e35dc0>
tensor(180.3288, device='cuda:0', grad_fn=<NllLossBackward0>) 80.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e35dc0>
tensor(97.5740, device='cuda:0', grad_fn=<NllLossBackward0>) 52.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2e35dc0>
[2023-10-24-11-36-05][epoch: 7] 83.997 sec train_loss 4.060, train_acc 0.612, valid_acc 0.799
tensor(108.1683, device='cuda:0', grad_fn=<NllLossBackward0>) 92.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0ed60>
tensor(53.4487, device='cuda:0', grad_fn=<NllLossBackward0>) 98.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0ed60>
tensor(75.2519, device='cuda:0', grad_fn=<NllLossBackward0>) 93.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0ed60>
tensor(131.0722, device='cuda:0', grad_fn=<NllLossBackward0>) 85.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0ed60>
tensor(74.4754, device='cuda:0', grad_fn=<NllLossBackward0>) 85.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a0ed60>
tensor(487.2236, device='cuda:0', grad_fn=<NllLossBackward0>) 52.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2a0ed60>
[2023-10-24-11-36-17][epoch: 8] 96.061 sec train_loss 1.423, train_acc 0.716, valid_acc 0.711
tensor(165.8247, device='cuda:0', grad_fn=<NllLossBackward0>) 76.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e958e0>
tensor(233.0726, device='cuda:0', grad_fn=<NllLossBackward0>) 81.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e958e0>
tensor(291.3690, device='cuda:0', grad_fn=<NllLossBackward0>) 82.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e958e0>
tensor(121.8525, device='cuda:0', grad_fn=<NllLossBackward0>) 80.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e958e0>
tensor(58.6020, device='cuda:0', grad_fn=<NllLossBackward0>) 97.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2e958e0>
tensor(69.9654, device='cuda:0', grad_fn=<NllLossBackward0>) 66.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2e958e0>
[2023-10-24-11-36-29][epoch: 9] 108.109 sec train_loss 1.031, train_acc 0.665, valid_acc 0.746
tensor(80.8184, device='cuda:0', grad_fn=<NllLossBackward0>) 83.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20a00>
tensor(64.1610, device='cuda:0', grad_fn=<NllLossBackward0>) 94.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20a00>
tensor(59.2586, device='cuda:0', grad_fn=<NllLossBackward0>) 102.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20a00>
tensor(72.5184, device='cuda:0', grad_fn=<NllLossBackward0>) 89.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20a00>
tensor(81.4125, device='cuda:0', grad_fn=<NllLossBackward0>) 93.0 128 19267584 <__main__.Accumulator object at 0x7fb8f2a20a00>
tensor(41.3903, device='cuda:0', grad_fn=<NllLossBackward0>) 60.0 80 12042240 <__main__.Accumulator object at 0x7fb8f2a20a00>
[2023-10-24-11-36-41][epoch: 10] 119.965 sec train_loss 0.587, train_acc 0.756, valid_acc 0.743
[Total 10 epochs] 122.092 sec train_loss 0.587, train_acc 0.000, valid_acc0.743
166.7 examples/sec on [device(type='cuda', index=0), device(type='cuda', index=1)]
