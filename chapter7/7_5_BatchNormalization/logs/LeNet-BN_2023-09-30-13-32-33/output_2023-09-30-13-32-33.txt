==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [10, 10]                  --
├─Conv2d: 1-1                            [10, 6, 24, 24]           156
├─BatchNorm2d: 1-2                       [10, 6, 24, 24]           12
├─Sigmoid: 1-3                           [10, 6, 24, 24]           --
├─AvgPool2d: 1-4                         [10, 6, 12, 12]           --
├─Conv2d: 1-5                            [10, 16, 8, 8]            2,416
├─BatchNorm2d: 1-6                       [10, 16, 8, 8]            32
├─Sigmoid: 1-7                           [10, 16, 8, 8]            --
├─AvgPool2d: 1-8                         [10, 16, 4, 4]            --
├─Flatten: 1-9                           [10, 256]                 --
├─Linear: 1-10                           [10, 120]                 30,840
├─BatchNorm1d: 1-11                      [10, 120]                 240
├─Sigmoid: 1-12                          [10, 120]                 --
├─Linear: 1-13                           [10, 84]                  10,164
├─BatchNorm1d: 1-14                      [10, 84]                  168
├─Sigmoid: 1-15                          [10, 84]                  --
├─Linear: 1-16                           [10, 10]                  850
==========================================================================================
Total params: 44,878
Trainable params: 44,878
Non-trainable params: 0
Total mult-adds (M): 2.87
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.75
Params size (MB): 0.18
Estimated Total Size (MB): 0.96
==========================================================================================
Conv2d output shape:	 torch.Size([10, 6, 24, 24])
BatchNorm2d output shape:	 torch.Size([10, 6, 24, 24])
Sigmoid output shape:	 torch.Size([10, 6, 24, 24])
AvgPool2d output shape:	 torch.Size([10, 6, 12, 12])
Conv2d output shape:	 torch.Size([10, 16, 8, 8])
BatchNorm2d output shape:	 torch.Size([10, 16, 8, 8])
Sigmoid output shape:	 torch.Size([10, 16, 8, 8])
AvgPool2d output shape:	 torch.Size([10, 16, 4, 4])
Flatten output shape:	 torch.Size([10, 256])
Linear output shape:	 torch.Size([10, 120])
BatchNorm1d output shape:	 torch.Size([10, 120])
Sigmoid output shape:	 torch.Size([10, 120])
Linear output shape:	 torch.Size([10, 84])
BatchNorm1d output shape:	 torch.Size([10, 84])
Sigmoid output shape:	 torch.Size([10, 84])
Linear output shape:	 torch.Size([10, 10])

learning_rate = 1.0, num_epochs = 10, batch_size = 256, 使用BN的高级API

training on cuda:0
0.8 sec, [epoch: 0] train_loss: 0.727, train_acc: 0.736, test_acc: 0.793
1.4 sec, [epoch: 1] train_loss: 0.464, train_acc: 0.830, test_acc: 0.693
2.1 sec, [epoch: 2] train_loss: 0.398, train_acc: 0.854, test_acc: 0.827
2.7 sec, [epoch: 3] train_loss: 0.365, train_acc: 0.868, test_acc: 0.823
3.3 sec, [epoch: 4] train_loss: 0.336, train_acc: 0.876, test_acc: 0.509
3.9 sec, [epoch: 5] train_loss: 0.317, train_acc: 0.883, test_acc: 0.832
4.5 sec, [epoch: 6] train_loss: 0.303, train_acc: 0.889, test_acc: 0.832
5.1 sec, [epoch: 7] train_loss: 0.288, train_acc: 0.893, test_acc: 0.826
5.7 sec, [epoch: 8] train_loss: 0.282, train_acc: 0.896, test_acc: 0.871
6.3 sec, [epoch: 9] train_loss: 0.269, train_acc: 0.901, test_acc: 0.860
[Total] loss 0.269, train acc 0.901,test acc 0.860
[Total] 6.3 sec, 94595.3 examples/secon cuda:0
