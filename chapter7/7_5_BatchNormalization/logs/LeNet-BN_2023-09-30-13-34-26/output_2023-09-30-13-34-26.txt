==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [10, 10]                  --
├─Conv2d: 1-1                            [10, 6, 24, 24]           156
├─BatchNorm2d: 1-2                       [10, 6, 24, 24]           12
├─Sigmoid: 1-3                           [10, 6, 24, 24]           --
├─AvgPool2d: 1-4                         [10, 6, 12, 12]           --
├─Conv2d: 1-5                            [10, 16, 8, 8]            2,416
├─BatchNorm2d: 1-6                       [10, 16, 8, 8]            32
├─Sigmoid: 1-7                           [10, 16, 8, 8]            --
├─AvgPool2d: 1-8                         [10, 16, 4, 4]            --
├─Flatten: 1-9                           [10, 256]                 --
├─Linear: 1-10                           [10, 120]                 30,840
├─BatchNorm1d: 1-11                      [10, 120]                 240
├─Sigmoid: 1-12                          [10, 120]                 --
├─Linear: 1-13                           [10, 84]                  10,164
├─BatchNorm1d: 1-14                      [10, 84]                  168
├─Sigmoid: 1-15                          [10, 84]                  --
├─Linear: 1-16                           [10, 10]                  850
==========================================================================================
Total params: 44,878
Trainable params: 44,878
Non-trainable params: 0
Total mult-adds (M): 2.87
==========================================================================================
Input size (MB): 0.03
Forward/backward pass size (MB): 0.75
Params size (MB): 0.18
Estimated Total Size (MB): 0.96
==========================================================================================
Conv2d output shape:	 torch.Size([10, 6, 24, 24])
BatchNorm2d output shape:	 torch.Size([10, 6, 24, 24])
Sigmoid output shape:	 torch.Size([10, 6, 24, 24])
AvgPool2d output shape:	 torch.Size([10, 6, 12, 12])
Conv2d output shape:	 torch.Size([10, 16, 8, 8])
BatchNorm2d output shape:	 torch.Size([10, 16, 8, 8])
Sigmoid output shape:	 torch.Size([10, 16, 8, 8])
AvgPool2d output shape:	 torch.Size([10, 16, 4, 4])
Flatten output shape:	 torch.Size([10, 256])
Linear output shape:	 torch.Size([10, 120])
BatchNorm1d output shape:	 torch.Size([10, 120])
Sigmoid output shape:	 torch.Size([10, 120])
Linear output shape:	 torch.Size([10, 84])
BatchNorm1d output shape:	 torch.Size([10, 84])
Sigmoid output shape:	 torch.Size([10, 84])
Linear output shape:	 torch.Size([10, 10])

learning_rate = 1.0, num_epochs = 10, batch_size = 256, 使用BN的高级API

training on cuda:0
0.8 sec, [epoch: 0] train_loss: 0.736, train_acc: 0.736, test_acc: 0.803
1.4 sec, [epoch: 1] train_loss: 0.463, train_acc: 0.832, test_acc: 0.838
2.0 sec, [epoch: 2] train_loss: 0.400, train_acc: 0.855, test_acc: 0.814
2.6 sec, [epoch: 3] train_loss: 0.357, train_acc: 0.869, test_acc: 0.851
3.2 sec, [epoch: 4] train_loss: 0.332, train_acc: 0.878, test_acc: 0.808
3.8 sec, [epoch: 5] train_loss: 0.310, train_acc: 0.886, test_acc: 0.699
4.4 sec, [epoch: 6] train_loss: 0.297, train_acc: 0.890, test_acc: 0.738
5.0 sec, [epoch: 7] train_loss: 0.284, train_acc: 0.895, test_acc: 0.870
5.6 sec, [epoch: 8] train_loss: 0.274, train_acc: 0.899, test_acc: 0.742
6.2 sec, [epoch: 9] train_loss: 0.264, train_acc: 0.903, test_acc: 0.886
[Total] loss 0.264, train acc 0.903,test acc 0.886
[Total] 6.2 sec, 96967.6 examples/secon cuda:0
