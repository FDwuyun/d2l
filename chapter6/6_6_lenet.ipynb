{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "493c2d92",
      "metadata": {
        "id": "493c2d92",
        "origin_pos": 0
      },
      "source": [
        "# 卷积神经网络（LeNet）\n",
        ":label:`sec_lenet`\n",
        "\n",
        "通过之前几节，我们学习了构建一个完整卷积神经网络的所需组件。\n",
        "回想一下，之前我们将softmax回归模型（ :numref:`sec_softmax_scratch`）和多层感知机模型（ :numref:`sec_mlp_scratch`）应用于Fashion-MNIST数据集中的服装图片。\n",
        "为了能够应用softmax回归和多层感知机，我们首先将每个大小为$28\\times28$的图像展平为一个784维的固定长度的一维向量，然后用全连接层对其进行处理。\n",
        "而现在，我们已经掌握了卷积层的处理方法，我们可以在图像中保留空间结构。\n",
        "同时，用卷积层代替全连接层的另一个好处是：模型更简洁、所需的参数更少。\n",
        "\n",
        "本节将介绍LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。\n",
        "这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），目的是识别图像 :cite:`LeCun.Bottou.Bengio.ea.1998`中的手写数字。\n",
        "当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，这项工作代表了十多年来神经网络研究开发的成果。\n",
        "\n",
        "当时，LeNet取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。\n",
        "LeNet被广泛用于自动取款机（ATM）机中，帮助识别处理支票的数字。\n",
        "时至今日，一些自动取款机仍在运行Yann LeCun和他的同事Leon Bottou在上世纪90年代写的代码呢！\n",
        "\n",
        "## LeNet\n",
        "\n",
        "总体来看，(**LeNet（LeNet-5）由两个部分组成：**)(~~卷积编码器和全连接层密集块~~)\n",
        "\n",
        "* 卷积编码器：由两个卷积层组成;\n",
        "* 全连接层密集块：由三个全连接层组成。\n",
        "\n",
        "该架构如 :numref:`img_lenet`所示。\n",
        "\n",
        "![LeNet中的数据流。输入是手写数字，输出为10种可能结果的概率。](http://d2l.ai/_images/lenet.svg)\n",
        ":label:`img_lenet`\n",
        "\n",
        "每个卷积块中的基本单元是一个卷积层、一个ReLU激活函数和平均汇聚层。请注意，虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现。每个卷积层使用$5\\times 5$卷积核和一个ReLU激活函数。这些层将输入映射到多个二维特征输出，通常同时增加通道的数量。第一卷积层有6个输出通道，而第二个卷积层有16个输出通道。每个$2\\times2$池操作（步幅2）通过空间下采样将维数减少4倍。卷积的输出形状由批量大小、通道数、高度、宽度决定。\n",
        "\n",
        "为了将卷积块的输出传递给稠密块，我们必须在小批量中展平每个样本。换言之，我们将这个四维输入转换成全连接层所期望的二维输入。这里的二维表示的第一个维度索引小批量中的样本，第二个维度给出每个样本的平面向量表示。LeNet的稠密块有三个全连接层，分别有120、84和10个输出。因为我们在执行分类任务，所以输出层的10维对应于最后输出结果的数量。\n",
        "\n",
        "通过下面的LeNet代码，可以看出用深度学习框架实现此类模型非常简单。我们只需要实例化一个`Sequential`块并将需要的层连接在一起。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "589980bb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:16:58.345112Z",
          "iopub.status.busy": "2023-08-18T07:16:58.344514Z",
          "iopub.status.idle": "2023-08-18T07:17:01.351069Z",
          "shell.execute_reply": "2023-08-18T07:17:01.349827Z"
        },
        "id": "589980bb",
        "origin_pos": 2,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(\n",
        "    # in.shape = (1, 1, 28, 28)\n",
        "    nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5, padding = 2), nn.ReLU(),\n",
        "    # padding的作用h, w 没变 out.shape = (1, 6, 28, 28)\n",
        "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "    # pooling通过空间下采样将维数减少2倍 out.shape = (1, 6, 14, 14)\n",
        "    nn.Conv2d(6, 16, kernel_size = 5), nn.ReLU(),\n",
        "    # out.shape = (1, 16, 10, 10)\n",
        "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "    # out.shape = (1, 16, 5, 5)\n",
        "    nn.Flatten(),\n",
        "    # out.shape = (1, 16 * 5 * 5 = 400)\n",
        "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
        "    # out.shape = (1, 120)\n",
        "    nn.Linear(120, 84), nn.ReLU(),\n",
        "    nn.Linear(84, 10)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b37131",
      "metadata": {
        "id": "b9b37131",
        "origin_pos": 5
      },
      "source": [
        "我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的LeNet-5一致。\n",
        "\n",
        "下面，我们将一个大小为$28 \\times 28$的单通道（黑白）图像通过LeNet。通过在每一层打印输出的形状，我们可以[**检查模型**]，以确保其操作与我们期望的 :numref:`img_lenet_vert`一致。\n",
        "\n",
        "![LeNet 的简化版。](https://github.com/d2l-ai/d2l-zh-pytorch-colab/blob/master/img/lenet-vert.svg?raw=1)\n",
        ":label:`img_lenet_vert`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d4dfb21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.355505Z",
          "iopub.status.busy": "2023-08-18T07:17:01.354784Z",
          "iopub.status.idle": "2023-08-18T07:17:01.371233Z",
          "shell.execute_reply": "2023-08-18T07:17:01.370166Z"
        },
        "id": "8d4dfb21",
        "origin_pos": 7,
        "outputId": "b81b1211-b8d9-4b0e-ca95-473fee2546a1",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "X = torch.rand(size = (1, 1, 28, 28), dtype = torch.float32)\n",
        "for layer in net:\n",
        "  X = layer(X)\n",
        "  print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81704149",
      "metadata": {
        "id": "81704149",
        "origin_pos": 10
      },
      "source": [
        "请注意，在整个卷积块中，与上一层相比，每一层特征的高度和宽度都减小了。\n",
        "第一个卷积层使用2个像素的填充，来补偿$5 \\times 5$卷积核导致的特征减少。\n",
        "相反，第二个卷积层没有填充，因此高度和宽度都减少了4个像素。\n",
        "随着层叠的上升，通道的数量从输入时的1个，增加到第一个卷积层之后的6个，再到第二个卷积层之后的16个。\n",
        "同时，每个汇聚层的高度和宽度都减半。最后，每个全连接层减少维数，最终输出一个维数与结果分类数相匹配的输出。\n",
        "\n",
        "## 模型训练\n",
        "\n",
        "现在我们已经实现了LeNet，让我们看看[**LeNet在Fashion-MNIST数据集上的表现**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i9QFBPFHANNf",
      "metadata": {
        "id": "i9QFBPFHANNf"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize = None):\n",
        "  \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
        "  # transforms.ToTensor()函数的作用是将原始的PILImage格式或者numpy.array格式的数据格式化为可被pytorch快速处理的张量类型。\n",
        "  # https://blog.csdn.net/qq_38410428/article/details/94719553\n",
        "  trans = [transforms.ToTensor()] # 实例化\n",
        "  if resize:\n",
        "    trans.insert(0, transforms.Resize(resize))\n",
        "  # 例如，我们需要对一张图片先进行尺度变换，再进行转化为Tensor算子。我们可以分步骤来，但是这样往往比较繁琐。\n",
        "  # 所以，我们可以利用Compose操作。实例时，我们传入一个列表，列表分别是几个实例化后的tansforms类，作为参数传入Compose中。\n",
        "  # 特别注意的是，compose中第一个操作后的数据，要符合第二个操作的输入类型。例如上中，第二个操作的输入是PIL类型，所以可以正常进行Totensor变换。\n",
        "  trans = transforms.Compose(trans)\n",
        "  mnist_train = torchvision.datasets.FashionMNIST(\n",
        "      root = \"../data\",\n",
        "      train = True,\n",
        "      transform = trans,\n",
        "      download = True\n",
        "  )\n",
        "  mnist_test = torchvision.datasets.FashionMNIST(\n",
        "      root = \"../data\",\n",
        "      train = False,\n",
        "      transform = trans,\n",
        "      download = True\n",
        "  )\n",
        "  return (\n",
        "      data.DataLoader(mnist_train, batch_size, shuffle = True, num_workers = 2),\n",
        "      data.DataLoader(mnist_test, batch_size, shuffle = False, num_workers = 2)\n",
        "  )\n",
        "print(\"Hello\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d13d15dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.375937Z",
          "iopub.status.busy": "2023-08-18T07:17:01.374923Z",
          "iopub.status.idle": "2023-08-18T07:17:01.483390Z",
          "shell.execute_reply": "2023-08-18T07:17:01.481932Z"
        },
        "id": "d13d15dc",
        "origin_pos": 11,
        "outputId": "d87ef35c-e886-474b-e544-1640969d5645",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f18ba4f",
      "metadata": {
        "id": "2f18ba4f",
        "origin_pos": 12
      },
      "source": [
        "虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。\n",
        "通过使用GPU，可以用它加快训练。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6cad2b",
      "metadata": {
        "id": "cf6cad2b",
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ]
      },
      "source": [
        "为了进行评估，我们需要[**对**] :numref:`sec_softmax_scratch`中描述的(**`evaluate_accuracy`函数进行轻微的修改**)。\n",
        "由于完整的数据集位于内存中，因此在模型使用GPU计算数据集之前，我们需要将其复制到显存中。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lePE1k8psPVU",
      "metadata": {
        "id": "lePE1k8psPVU"
      },
      "outputs": [],
      "source": [
        "class Accumulator:\n",
        "    \"\"\"在n个变量上累加\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "    \"\"\"计算预测正确的数量\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)# 获得每行中最大元素的索引来获得预测类别\n",
        "    cmp = y_hat.type(y.dtype) == y#\n",
        "    return float(cmp.type(y.dtype).sum())# 返回预测正确的个数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c868f5c5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.489623Z",
          "iopub.status.busy": "2023-08-18T07:17:01.488809Z",
          "iopub.status.idle": "2023-08-18T07:17:01.498984Z",
          "shell.execute_reply": "2023-08-18T07:17:01.498112Z"
        },
        "id": "c868f5c5",
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy_gpu(net, data_iter, device = None):\n",
        "  \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "    net.eval() # 设置为评估模式，关闭Dropout和直接结算所有batch的均值和方差\n",
        "    if not device:\n",
        "      # 使用参数来构建一个虚拟的计算图，然后从计算图中获取一个参数张量，然后通过 .device 属性获取这个参数张量所在的设备。这个参数张量位于模型的第一个参数（通常是一个权重矩阵）。\n",
        "      device = next(iter(net.parameters())).device\n",
        "  # 正确预测的数量，总预测的数量\n",
        "  metric = Accumulator(2)\n",
        "  with torch.no_grad():\n",
        "    for X, y in data_iter:\n",
        "      if isinstance(X, list):\n",
        "        # BERT微调所需要的\n",
        "        X = [x.to(device) for x in X]\n",
        "      else:\n",
        "        X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      metric.add(accuracy(net(X), y), y.numel())\n",
        "  return metric[0] / metric[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2872a69",
      "metadata": {
        "id": "d2872a69",
        "origin_pos": 17
      },
      "source": [
        "[**为了使用GPU，我们还需要一点小改动**]。\n",
        "与 :numref:`sec_softmax_scratch`中定义的`train_epoch_ch3`不同，在进行正向和反向传播之前，我们需要将每一小批量数据移动到我们指定的设备（例如GPU）上。\n",
        "\n",
        "如下所示，训练函数`train_ch6`也类似于 :numref:`sec_softmax_scratch`中定义的`train_ch3`。\n",
        "由于我们将实现多层神经网络，因此我们将主要使用高级API。\n",
        "以下训练函数假定从高级API创建的模型作为输入，并进行相应的优化。\n",
        "我们使用在 :numref:`subsec_xavier`中介绍的Xavier随机初始化模型参数。\n",
        "与全连接层一样，我们使用交叉熵损失函数和小批量随机梯度下降。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TIMQ9r3xD4Wn",
      "metadata": {
        "id": "TIMQ9r3xD4Wn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "class Timer:\n",
        "    \"\"\"记录多次运行时间\"\"\"\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.start()\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"启动计时器\"\"\"\n",
        "        self.tik = time.time()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n",
        "        self.times.append(time.time() - self.tik)\n",
        "        return self.times[-1]\n",
        "\n",
        "    def avg(self):\n",
        "        \"\"\"返回平均时间\"\"\"\n",
        "        return sum(self.times) / len(self.times)\n",
        "\n",
        "    def sum(self):\n",
        "        \"\"\"返回时间总和\"\"\"\n",
        "        return sum(self.times)\n",
        "\n",
        "    def cumsum(self):\n",
        "        \"\"\"返回累计时间\"\"\"\n",
        "        return np.array(self.times).cumsum().tolist()\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib_inline import backend_inline\n",
        "\n",
        "def use_svg_display():\n",
        "    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n",
        "    #可以试试加上这个代码，%config InlineBackend.figure_format = 'svg'\n",
        "    backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "def set_figsize(figsize=(3.5, 2.5)):\n",
        "    \"\"\"设置matplotlib的图表大小\"\"\"\n",
        "    use_svg_display()\n",
        "    plt.rcParams['figure.figsize'] = figsize\n",
        "\n",
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"设置matplotlib的轴\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()\n",
        "\n",
        "#通过以上三个用于图形配置的函数，定义一个plot函数来简洁地绘制多条曲线， 因为我们需要在整个书中可视化许多曲线。\n",
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "         ylim=None, xscale='linear', yscale='linear',\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
        "    \"\"\"绘制数据点\"\"\"\n",
        "    if legend is None:\n",
        "        legend = []\n",
        "\n",
        "    set_figsize(figsize)\n",
        "    axes = axes if axes else plt.gca()\n",
        "\n",
        "    # 如果X有一个轴，输出True\n",
        "    def has_one_axis(X):\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
        "                and not hasattr(X[0], \"__len__\"))\n",
        "\n",
        "    if has_one_axis(X):\n",
        "        X = [X]\n",
        "    if Y is None:\n",
        "        X, Y = [[]] * len(X), X\n",
        "    elif has_one_axis(Y):\n",
        "        Y = [Y]\n",
        "    if len(X) != len(Y):\n",
        "        X = X * len(Y)\n",
        "    axes.cla()\n",
        "    for x, y, fmt in zip(X, Y, fmts):\n",
        "        if len(x):\n",
        "            axes.plot(x, y, fmt)\n",
        "        else:\n",
        "            axes.plot(y, fmt)\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "\n",
        "\n",
        "class Animator:\n",
        "    \"\"\"在动画中绘制数据\"\"\"\n",
        "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "                 ylim=None, xscale='linear', yscale='linear',\n",
        "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
        "                 figsize=(3.5, 2.5)):\n",
        "        # 增量地绘制多条线\n",
        "        if legend is None:\n",
        "            legend = []\n",
        "        use_svg_display()\n",
        "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "        if nrows * ncols == 1:\n",
        "            self.axes = [self.axes, ]\n",
        "        # 使用lambda函数捕获参数\n",
        "        self.config_axes = lambda: set_axes(\n",
        "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
        "        self.X, self.Y, self.fmts = None, None, fmts\n",
        "\n",
        "    def add(self, x, y):\n",
        "        # 向图表中添加多个数据点\n",
        "        if not hasattr(y, \"__len__\"):\n",
        "            y = [y]\n",
        "        n = len(y)\n",
        "        if not hasattr(x, \"__len__\"):\n",
        "            x = [x] * n\n",
        "        if not self.X:\n",
        "            self.X = [[] for _ in range(n)]\n",
        "        if not self.Y:\n",
        "            self.Y = [[] for _ in range(n)]\n",
        "        for i, (a, b) in enumerate(zip(x, y)):\n",
        "            if a is not None and b is not None:\n",
        "                self.X[i].append(a)\n",
        "                self.Y[i].append(b)\n",
        "        self.axes[0].cla()\n",
        "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
        "            self.axes[0].plot(x, y, fmt)\n",
        "        self.config_axes()\n",
        "        display.display(self.fig)\n",
        "        display.clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cb06c53",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.504092Z",
          "iopub.status.busy": "2023-08-18T07:17:01.503194Z",
          "iopub.status.idle": "2023-08-18T07:17:01.520331Z",
          "shell.execute_reply": "2023-08-18T07:17:01.519209Z"
        },
        "id": "8cb06c53",
        "origin_pos": 19,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
        "  \"\"\"用GPU训练模型（在第六章定义）\"\"\"\n",
        "  def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "      nn.init.xavier_uniform_(m.weight)\n",
        "  net.apply(init_weights)\n",
        "  print('training on', device)\n",
        "  net.to(device)\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
        "  loss = nn.CrossEntropyLoss()\n",
        "  animator = Animator(xlabel = 'epoch', xlim = [1, num_epochs],\n",
        "                      legend = ['train loss', 'train acc', 'test acc'])\n",
        "  timer, num_batches = Timer(), len(train_iter)\n",
        "  for epoch in range(num_epochs):\n",
        "    # 训练损失之和，训练准确率之和，样本数\n",
        "    metric = Accumulator(3)\n",
        "    net.train()\n",
        "    for i, (X, y) in enumerate(train_iter):\n",
        "      timer.start()\n",
        "      optimizer.zero_grad()\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_hat = net(X)\n",
        "      l = loss(y_hat, y)\n",
        "      l.backward()\n",
        "      optimizer.step()\n",
        "      with torch.no_grad():\n",
        "        # 这部分代码计算了当前批次的损失乘以批次的大小（样本数量）。\n",
        "        # 这是为了得到当前批次的总损失。通常，损失是对单个样本的损失，将其乘以批次大小可以得到批次的总损失。\n",
        "        metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
        "      timer.stop()\n",
        "      train_l = metric[0] / metric[2]\n",
        "      train_acc = metric[1] / metric[2]\n",
        "      if (i + 1) % (num_batches // 20) == 0 or i == num_batches - 1:\n",
        "        animator.add(epoch + (i + 1) / num_batches,\n",
        "                     (train_l, train_acc, None))\n",
        "      test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
        "      animator.add(epoch + 1, (None, None, test_acc))\n",
        "  print(f'loss {train_l:.3f}, train acc {train_acc:.3f},'\n",
        "      f'test acc {test_acc:.3f}')\n",
        "  # 每秒处理的样本数量\n",
        "  print(f'{timer.sum():.1f} sec, {metric[2] * num_epochs / timer.sum():.1f} examples/sec'\n",
        "      f'on {str(device)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d212797",
      "metadata": {
        "id": "1d212797",
        "origin_pos": 22
      },
      "source": [
        "现在，我们[**训练和评估LeNet-5模型**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1G0V_s1YFhaf",
      "metadata": {
        "id": "1G0V_s1YFhaf"
      },
      "outputs": [],
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58dd36f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def try_all_gpus():\n",
        "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "try_all_gpus()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5d7b0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "execution": {
          "iopub.execute_input": "2023-08-18T07:17:01.525559Z",
          "iopub.status.busy": "2023-08-18T07:17:01.524508Z",
          "iopub.status.idle": "2023-08-18T07:17:54.484626Z",
          "shell.execute_reply": "2023-08-18T07:17:54.483337Z"
        },
        "id": "4b5d7b0c",
        "origin_pos": 23,
        "outputId": "510d6898-d4c9-4c4e-99bc-678810d2a458",
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "lr, num_epochs = 0.009, 10\n",
        "train_ch6(net, train_iter, test_iter, num_epochs, lr, try_gpu())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e19273b3",
      "metadata": {},
      "source": [
        "1. 记录\n",
        "\n",
        "|  |  |  |\n",
        "| :----: | :----:| :----: |\n",
        "| lr, num_epochs = 0.2, 10 | lr, num_epochs = 0.9, 10 | 单元格 |\n",
        "| 平均汇聚层 | 平均汇聚层 | 单元格 |\n",
        "| <img src=\"image.png\" style=\"zoom:80%;\" />  | <img src=\"image-1.png\" style=\"zoom:80%;\" /> | 单元格 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4db919b",
      "metadata": {
        "id": "d4db919b",
        "origin_pos": 24
      },
      "source": [
        "## 小结\n",
        "\n",
        "* 卷积神经网络（CNN）是一类使用卷积层的网络。\n",
        "* 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。\n",
        "* 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。\n",
        "* 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。\n",
        "* LeNet是最早发布的卷积神经网络之一。\n",
        "\n",
        "## 练习\n",
        "\n",
        "1. 将平均汇聚层替换为最大汇聚层，会发生什么？\n",
        "1. 尝试构建一个基于LeNet的更复杂的网络，以提高其准确性。\n",
        "    1. 调整卷积窗口大小。\n",
        "    1. 调整输出通道的数量。\n",
        "    1. 调整激活函数（如ReLU）。\n",
        "    1. 调整卷积层的数量。\n",
        "    1. 调整全连接层的数量。\n",
        "    1. 调整学习率和其他训练细节（例如，初始化和轮数）。\n",
        "1. 在MNIST数据集上尝试以上改进的网络。\n",
        "1. 显示不同输入（例如毛衣和外套）时，LeNet第一层和第二层的激活值。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bb384b2",
      "metadata": {},
      "source": [
        "1. \n",
        "|使用最大汇聚层| 使用最大汇聚层 \n",
        "| :----: | :----:\n",
        "| lr, num_epochs = 0.2, 10 | lr, num_epochs = 0.9, 10 \n",
        "| nn.MaxPool2d(kernel_size = 2, stride = 2) | nn.MaxPool2d(kernel_size = 2, stride = 2) \n",
        "| ![Alt text](image-2.png)  | ![Alt text](image-4.png) \n",
        "| | \n",
        "\n",
        "\n",
        "| 最大汇聚层 | 最大汇聚层\n",
        "| :----: | :----:\n",
        "| 使用ReLU激活函数 | ReLU激活函数 + 均方损失函数 nn.MSELoss()\n",
        "| ![Alt text](image-5.png) | 报错\n",
        "| 梯度消失 | \n",
        "\n",
        "- 把lr调小就可以很快收敛，0.9这个学习率对于ReLU来说太大了。我觉得可能是因为ReLU在0的右邻域内的梯度比sigmoid大得多，所以适用于sigmoid的lr用在ReLU身上容易步子迈太大，走过头，反而不好收敛。学习率过大导致参数一直在目标附近来回震荡而落不下去。\n",
        "- lr = 0.09,  optimizer = torch.optim.Adam(net.parameters(), lr = lr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "required_libs": []
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
